{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----------------------------------------------------Section - 2-----------------------------------------------------------\n",
    "###                              2) Coventional Machine Learning Model - Naive Base Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Base Classifier:\n",
    "In this Project of Image classification we need to predict whether a particular celeb has a Black, Brown, Gray, Blond. the data that we have is in the range of 0 to 255 for each feature and there are 6912 features in total. so we are normalizing the data such that it now has a mean 0 and variation 1 meaning the data lies with in 0 and 1.\n",
    "\n",
    "Naive Base classifier is of two types:\n",
    "1. Gaussian Naive Base: \n",
    "Gaussian Naive base is used when we need to estimate mean and standard deviation from the features.\n",
    "2. Multinomial Naive BAse: \n",
    "Multinomial Naive Base is suitable for classification with features having discrete values.\n",
    "\n",
    "Since, the data that we are dealing in this project is Continuous data for all features we will use Gausiian Naive Base classifier for this clasification"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step-1: Importing all the necessry Python packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "from os.path import join\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step-2: Loading the Training DataSet, exploring the data and Normalizing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After reshaping image train shape is: (98479, 48, 48, 3)\n",
      "After reshaping image train data is: [[[0.99215686 0.90588235 0.76078431]\n",
      "  [0.99215686 0.90588235 0.76078431]\n",
      "  [0.99215686 0.90588235 0.76078431]\n",
      "  ...\n",
      "  [0.54901961 0.37254902 0.27843137]\n",
      "  [0.87843137 0.79607843 0.59607843]\n",
      "  [1.         0.94117647 0.89411765]]\n",
      "\n",
      " [[0.99215686 0.90588235 0.76078431]\n",
      "  [0.99215686 0.90588235 0.76078431]\n",
      "  [0.99215686 0.90588235 0.76078431]\n",
      "  ...\n",
      "  [0.64705882 0.48627451 0.34901961]\n",
      "  [0.93333333 0.86666667 0.7254902 ]\n",
      "  [0.99607843 0.94117647 0.89019608]]\n",
      "\n",
      " [[0.99215686 0.90588235 0.76078431]\n",
      "  [0.99215686 0.90588235 0.76078431]\n",
      "  [0.99215686 0.90588235 0.76078431]\n",
      "  ...\n",
      "  [0.75686275 0.61568627 0.41176471]\n",
      "  [0.97647059 0.91764706 0.85098039]\n",
      "  [0.98039216 0.94117647 0.8745098 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.82352941 0.54117647 0.38039216]\n",
      "  [0.76862745 0.50588235 0.3372549 ]\n",
      "  [0.4745098  0.23921569 0.12156863]\n",
      "  ...\n",
      "  [0.57254902 0.37647059 0.31764706]\n",
      "  [0.6        0.39607843 0.34901961]\n",
      "  [0.63529412 0.42745098 0.36862745]]\n",
      "\n",
      " [[0.72941176 0.4745098  0.28235294]\n",
      "  [0.56862745 0.30196078 0.16078431]\n",
      "  [0.40392157 0.14901961 0.06666667]\n",
      "  ...\n",
      "  [0.38431373 0.14509804 0.05490196]\n",
      "  [0.4        0.16470588 0.08235294]\n",
      "  [0.42745098 0.2        0.12156863]]\n",
      "\n",
      " [[0.64313725 0.37647059 0.19215686]\n",
      "  [0.64313725 0.36470588 0.22352941]\n",
      "  [0.41568627 0.15686275 0.0627451 ]\n",
      "  ...\n",
      "  [0.47843137 0.20392157 0.09019608]\n",
      "  [0.45098039 0.18431373 0.0745098 ]\n",
      "  [0.43137255 0.16862745 0.0627451 ]]]\n"
     ]
    }
   ],
   "source": [
    "# preliminary data Exploration \n",
    "hair_colours = ['black', 'blond', 'brown', 'gray']\n",
    "dataset_directory = 'C:\\\\Users\\\\suhas\\\\Downloads\\\\ML Practice\\\\image_dataset'  ## CHANGE TO YOUR OWN DIRECTORY\n",
    "\n",
    "images_train = np.load(join(dataset_directory, 'train_images.npy'))\n",
    "labels_train = np.load(join(dataset_directory, 'train_labels.npy'))\n",
    "\n",
    "image_size = 48\n",
    "images_train_rs = images_train.reshape([-1, image_size, image_size, 3]) / 255.0\n",
    "print(\"After reshaping image train shape is:\",images_train_rs.shape)\n",
    "print(\"After reshaping image train data is:\",images_train_rs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations From preliminary data Exploration:\n",
    "so we can see that images_train contains a list of size 98479 with 48 features as height for each picture, 48 features as width for each picture and a 3 channel (RGB) colour sclae for each picture (with values raning from 1 to 255). This results in 48*48*3 = 6912 features to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6912"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features = images_train_rs.shape[1]*images_train_rs.shape[2]*images_train_rs.shape[3]\n",
    "Features   # Calculating no of featurs required per picture"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step-3: Reshaping the Images_train data from 4D (98479, 48, 48, 3) to 2D (98479, 6912) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(98479, 6912)\n"
     ]
    }
   ],
   "source": [
    "# Reshaping using Reshape()\n",
    "lst1 = [None] * images_train_rs.shape[0] # creating an empty array of size 98479\n",
    "for i in range(images_train_rs.shape[0]):\n",
    "    lst1[i] = images_train_rs[i].reshape([-1]) # reshaping each picture to 6912 features and storing it in lst1\n",
    "#print(lst)\n",
    "x = np.array(lst1).reshape(images_train_rs.shape[0],Features) # converting the list to an array\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Train_Images data:  \n",
    "we now have the trian data in the form which is accepted by all Machine learning Models (which is 98479, 6912). we can use either the x coming from reshape() for training the model. we do not need to reshape labels_train because it contains single column with 98479 values."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step-4: Loading the Validation DataSet and exploring the data and repeat all the steps performed for training_images data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_val = np.load(join(dataset_directory, 'val_images.npy'))\n",
    "labels_val = np.load(join(dataset_directory, 'val_labels.npy'))\n",
    "files_val = np.load(join(dataset_directory, 'val_files.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_val_rs = images_val.reshape([-1, image_size, image_size, 3]) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations From preliminary data Exploration:\n",
    "so we can see that images_val contains a list of size 12270 with 48 features as height for each picture, 48 features as width for each picture and a 3 channel (RGB) colour sclae for each picture (with values raning from 1 to 255). This results in 48*48*3 = 6912 features to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6912"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features1 = images_val_rs.shape[1]*images_val_rs.shape[2]*images_val_rs.shape[3]\n",
    "Features1  # calculating the no of features for each picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12270, 6912)\n"
     ]
    }
   ],
   "source": [
    "lst3 = [None] * images_val_rs.shape[0] # creating an empty array of size 12270\n",
    "for i in range(images_val_rs.shape[0]):\n",
    "    lst3[i] = images_val_rs[i].reshape([-1])  # reshaping each picture to 6912 features and storing it in lst3\n",
    "\n",
    "y = np.array(lst3).reshape(images_val_rs.shape[0],Features1)  # converting the list to an array\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Val_Images data:  \n",
    "we now have the validation data in the form which is accepted by all Machine learning Models (which is 12270, 6912). we can use y coming from reshape() for validating the model. we do not need to reshape labels_val because it contains single column with 12270 values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting: \n",
    "we now have the Train_images in variable x, Val_images in y, labels_train, labels_val, so we can go further to fit the model using the training data and validate the model using the validation data. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step-5: Importing Gaussian Naive Base classifier and the accuracy score matrices to fit the model with default parametes"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Gaussian Naive Base do not take any parameters, so running with the default parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required below code in final merge file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for validation is: 0.5748981255093725\n"
     ]
    }
   ],
   "source": [
    "# Importing and fitting Gaussian Naive Base classifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = GaussianNB()\n",
    "model = model.fit(x, labels_train)\n",
    "val_pred = model.predict(y)\n",
    "print(\"Accuracy score for validation is:\",accuracy_score(labels_val, val_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### we can see that the Accuray score for Validation is 57.48% with Gaussian Naive base. By looking at this score we can say that the model is not performing good."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step-6: Loading the test DataSet, exploring the data and repeat all the steps performed for training_images data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the test data files\n",
    "images_test_public = np.load(join(dataset_directory, 'test_public_images.npy'))\n",
    "files_test_public = np.load(join(dataset_directory, 'test_public_files.npy'))\n",
    "images_test_public_rs = images_test_public.reshape([-1, image_size, image_size, 3]) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Observations From preliminary data Exploration:\n",
    "so we can see that images_test contains a list of size 11921 with 48 features as height for each picture, 48 features as width for each picture and a 3 channel (RGB) colour sclae for each picture (with values raning from 1 to 255). This results in 48*48*3 = 6912 features to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6912"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features3 = images_test_public_rs.shape[1]*images_test_public_rs.shape[2]*images_test_public_rs.shape[3]\n",
    "Features3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11921, 6912)\n"
     ]
    }
   ],
   "source": [
    "lst4 = [None] * images_test_public_rs.shape[0] # creating an empty array of size 98479\n",
    "for i in range(images_test_public_rs.shape[0]):\n",
    "    lst4[i] = images_test_public_rs[i].reshape([-1])  # reshaping each picture to 6912 features and storing it in lst1\n",
    "\n",
    "z = np.array(lst4).reshape(images_test_public_rs.shape[0],Features3)  # converting the list to an array\n",
    "print(z.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Test_Images data:  \n",
    "we now have the test data in the form which is accepted by all Machine learning Models (which is 11921, 6912). we can use this for predicting the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required every thing from this point in final file"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step-7: Final Model Fitting and predicting the values for test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final model fitting and predicting\n",
    "model = GaussianNB()\n",
    "model = model.fit(x, labels_train)\n",
    "Test_pred = model.predict(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11921"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11916</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11918</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11919</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11920</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction\n",
       "11916           1\n",
       "11917           3\n",
       "11918           0\n",
       "11919           2\n",
       "11920           1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a data frame for predicted values\n",
    "df1 = pd.DataFrame(Test_pred, columns=['Prediction'])\n",
    "df1.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11916</th>\n",
       "      <td>202595.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>202596.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11918</th>\n",
       "      <td>202597.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11919</th>\n",
       "      <td>202598.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11920</th>\n",
       "      <td>202599.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID\n",
       "11916  202595.jpg\n",
       "11917  202596.jpg\n",
       "11918  202597.jpg\n",
       "11919  202598.jpg\n",
       "11920  202599.jpg"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a data frame for files_val which contains image names\n",
    "df2 = pd.DataFrame(files_test_public, columns=['ID'])\n",
    "df2.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11916</th>\n",
       "      <td>202595.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11917</th>\n",
       "      <td>202596.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11918</th>\n",
       "      <td>202597.jpg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11919</th>\n",
       "      <td>202598.jpg</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11920</th>\n",
       "      <td>202599.jpg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               ID  Prediction\n",
       "11916  202595.jpg           1\n",
       "11917  202596.jpg           3\n",
       "11918  202597.jpg           0\n",
       "11919  202598.jpg           2\n",
       "11920  202599.jpg           1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining the two data frames through the index\n",
    "GaussianNB_TestPublicData_45693242 = df2.merge(df1, left_index=True, right_index=True)\n",
    "GaussianNB_TestPublicData_45693242.tail()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Step-10: Uploading the data Frame to a CSV File Named \"GaussianNB_TestPublicData_45693242.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "GaussianNB_TestPublicData_45693242.to_csv (r'C:\\\\Users\\\\suhas\\\\Downloads\\\\ML Practice\\\\GaussianNB_TestPublicData_45693242.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
